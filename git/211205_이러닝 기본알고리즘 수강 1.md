# 가장 기본이 되는 자료구조 : 스택과 큐



## 스택 자료구조

- 먼저 들어 온 데이터가 나중에 나가는 형식 (선입후출)의 자료구조

- `입구와 출구가 동일한 형태`로 스택을 시각화 할 수 있다.

- ``` python
  stack = []
  stack.append(5)
  stack.append(2)
  stack.append(3)
  stack.append(7)
  stack.pop()
  stack.append(1)
  stack.append(4)
  stack.pop()
  
  print(stack[::-1]) # 최상단 원소부터 출력
  print(stack) # 최하단 원소부터 출력
  ```



## 큐 자료구조

- 먼저 들어 온 데이터가 나가는 형식(선입선출)의 자료구조

- 큐는 입구와 출구가 모두 뚫려 있는 터널과 같은 형태로 시각화

- ``` python
  from collections import deque
  # 큐(Queue) 구현을 위해 deque 라이브러리 사용
  queue.deque()
  queue.append(5)
  queue.append(2)
  queue.appned(3)
  queue.append(7)
  queue.popleft()
  queue.append(1)
  queue.append(4)
  queue.popleft()
  print(queue) # 먼저 들어온 순서대로 출력
  queue.reverse() # 역순으로 바꾸기
  print(queue) # 나중에 들어온 원소부터 출력
  ```



### 우선순위 큐(Priority Queue)

- 우선순위 큐는 `우선순위가 가장 높은 데이터를 가장 먼저 삭제하는 자료`

- 우선순위 큐는 데이터를 `우선순위에 따라`처리하고 싶을 때 사용

  ex) 물건 데이터를 자료구조에 넣었다가 가치가 높은 물건부터 꺼내서 확인

  | 자료구조                    | 추출되는데이터              |
  | --------------------------- | --------------------------- |
  | 스택(Stack)                 | 가장 나중에 삽입된 데이터   |
  | 큐(Queue)                   | 가장 먼저 삽입된 데이터     |
  | 우선순위 큐(Priority Queue) | 가장 우선순위가 높은 데이터 |

- 우선순위 큐를 구현하는 방법은 다양

  - 단순히 `리스트를 이용하여 구현`
  - `힙(heap)을 이용하여 구현` 

- 데이터의 개수가 N개일 때, 구현 방식에 따라서 시간 복잡도를 비교

  | 우선순위 큐 구현 방식 | 삽입 시간 | 삭제 시간 |
  | --------------------- | --------- | --------- |
  | 리스트                | O(1)      | O(N)      |
  | 힙(Heap)              | O(logN)   | O(logN)   |

- 단순히 N개의 데이터를 힙에 넣었다가 모두 꺼내는 작업은 정렬과 동일 `(힙 정렬)`
  - 이 경우 시간 복잡도는 `O(NlogN)`



## 힙(Heap) 의 특징

- 힙은 완전 이진 트리 자료구조의 일종
- 힙에서는 항상 `루트 노드(root node)를 제거`
- `최소 힙(min heap)`
  - 루트 노드가 가장 작은 값을 가진다
  - 따라서 값이 작은 데이터가 우선적으로 제거
- `최대 힙(max heap)`
  - 루트 노드가 가장 큰 값을 가진다
  - 따라서 값이 큰 데이터가 우선적으로 제거



### 완전 이진 트리 (Complete Binary Tree)

- `완전 이진 트리`란 루트(root) 노드부터 시작하여 왼쪽 자식 노드, 오른쪽 자식 노드 순서대로 데이터가 차례대로 삽입되는 트리(tree)
- 최소 힙 구성 함수 : `Min-Heapify()`
  - (상향식) 부모 노드로 거슬로 올라가며, 부모보다 자신의 값이 더 작은 경우에 위치를 교체

- 새로운 원소가 삽입되었을 때 `O(logN)`의 시간 복잡도로 힙 성질을 유지

- 힙에서 원소가 제거될 때 `O(logN)`의 시간 복잡도로 힙 성질을 유지

  - 원소를 제거할 때는 가장 마지막 노드가 루트 노드의 위치

  - 이후에 루트 노드에서 하향식으로(더 작은 자식 노드) Heapify()를 진행

- 우선순위 큐 라이브러리를 활용 한 예제

  ```python
  import sys
  import heapq
  input = sys.stdin.readline
  
  def heapsort(iterable):
  	h = []
  	result = []
  	# 모든 원소를 차례대로 힙에 삽입
  	for value in iterable:
  		heapq.heappush(h,value)
      # 힙에 삽입된 모든 원소를 차례대로 꺼내어 담기
      for i in range(len(h)):
      	result.append(heapq.heappop(h))
      return result
  n = int(input())
  arr = []
  for i in range(n):
  	arr.append(int(input()))
  res = heapsort(arr)
  for i in range(n):
  	print(res[i])
  # 파이썬은 자동적으로 minheap(오름차순)으로 적용됨
  ```



## 트리(Tree)

- 트리는 가계도와 같은 `계층적인 구조`를 표현할 때 사용할 수 있는 자료구조
- [트리 관련 용어]
  - 루트 노드(root node): 부모가 없는 최상위 노드
  - 단말 노드(leaf node): 자식이 없는 노드 (가장 아래쪽)
  - 크기(size): 트리에 포함된 모든 노드의 개수
  - 깊이(depth): 루트 노드부터의 거리(최상단은 0~)
  - 높이(height): 깊이 중 최댓값
  - 차수(degree): 각 노드의(자식 방향) 간선 개수
- 기본적으로 트리의 크기가 N일 때, 전체 간선의 개수는 N-1개

### 이진 탐색 트리(Binary Search Tree)

- 이진 `탐색`이 동작할 수 있도록 고안된 효율적인 탐색이 가능한 자료구조
- 이진 탐색 트리의 특징 : 왼쪽 자식 노드 < 부모 노드 < 오른쪽 자식 노드
  - 부모 노드보다 왼쪽 자식 노드가 작습니다.
  - 부모 노드보다 오른쪽 자식 노드가 큽니다.

- 이진 탐색 트리가 이미 구성되어 있다고 가정하고 데이터를 조회하는 과정
  1. 루트 노드부터 방문하여 탐색을 진행
  2. 현재 노드와 값을 비교
  3. 원소를 찾으면 탐색을 종료
- 트리의 순회 (Tree Traversal)
  - 트리 자료 구조에 포함된 노드를 특정한 방법으로 한 번씩 방문
    - 트리의 정보를 시각적으로 확인
  - `대표적인 트리 순회` 방법
    - `전위 순회(pre-order traverse)` : 루트를 먼저 방문
    - `중위 순회(in-order traverse)` : 왼쪽 자식을 방문한 뒤에 루트를 방문
    - `후위 순회(post-order traverse)`: 오른쪽 자식을 방문한 뒤에 루트를 방문

- ```python
  class Node:
  	def ___init___(self, data, left_node, right_node):
  		self.data = data
  		self.left_node = left.node
  		self.right.node = right.node
  # 전위 순회(preorder Traversal)
  def pre_order(node):
  	print(node.data, end=' ')
  	if node.left_node !=None:
  		pre_order(tree[node.left_node])
  	if node.right_node != None:
  		pre_order(tree[node.right_node])
  # 중위 순회(Inorder Traversal)
  def in_order(node):
  	if node.left_node !=None:
  		in_order(tree[node.left_node])
  	print(node.data, end=' ')
  	if node.right_node !=None:
  		in_order(tree[node.right_node])
  #후위 순회(Postorder Traversal)
  def post_order(node):
  	if node.left_none !=None:
  		post_order(tree[node.left_node])
  	if node.right_node !=None:
  		post_order(tree[node.right_node])
  	print(node.data, end' ')
  n = int(input())
  tree = {}
  for i in range(n):
  	data, left_node, right_node = input(),  split()
  	if left_node == "None":
  		left_node = None
  	if right_node == "None""
  		right_node = None
  	tree[data] - Node(data, left_node, right_node)
  pre_order(tree['A'])
  pritn()
  in_order(tree['A'])
  print()
  post_order(tree['A'])
  ```



## 바이너리 인덱스트리

- `바이너스 인덱스 트리(binary indexed tree)`는 2진법 인덱스 구조를 활용해 구간 합 문제를 효과적으로 해결해 줄 수 있는 자료구조

  - `펜윅 트리(fenwick tree)`라고도 한다

- 정수에 따른 2진수 표기

  | 정수 | 2진수표기                          |
  | ---- | ---------------------------------- |
  | 7    | 00000000 00000000 00000000 0000111 |
  | -7   | 11111111 11111111 11111111 1111001 |

- 0이 아닌 마지막 비트를 찾는 방법

  - 특정한 숫자 K의 0이 아닌 마지막 비트를 찾기 위해서 K&-K를 계산하면 된다.

  - ``` python
    n = 8
    for i in range(n+i):
    	print(i, "의 마지막 비트:", (i&-i))
    ```

- 트리 구조 만들기 : 0이 아닌 마지막 비트 = 내가 저장하고 있는 값들의 개수

- 특정 값을 변경할 때 : 0이 아닌 마지막 비트만큼 더하면서 구간들의 값을 변경 (Update)

- 누적 합(Prefix Sum) 

  - `1부터 N까지의 합(누적 합) 구하기`: 0이 아닌 마지막 비트만큼 빼면서 구간들의 값의 합 계산

- ``` python
  import sys
  input = sys.stdin.readline
  # 데이터의 개수(n), 변경 횟수(m), 구간 합 계산 횟수(k)
  n, m, k = map(int, input().split())
  #전체 데이터의 개수는 최대 1,000,000개
  arr = [0] * (n+1)
  tree = [0] * (n+1)
  # i번째 수까지의 누적 합을 계산하는 함수
  def prefix_sum(i):
  	result = 0
  	while i >0:
  		result += tree[i]
  		# 0이 아닌 마지막 비트만큼 빼가면서 이동
  		i -= (i & -i)
  	return result
  # i번째 수를 dif만큼 더하는 함수
  def update(i,dif):
  	while i <= n:
  		tree[i] += dif
  		i += (i &-i)
  # start부터 end까지의 구간 합을 계산하는 함수
  def interval_sum(start, end):
  	return prefix_sum(end) - prefix_sum(start-1)
  for i inragne(1, n+1):
  	x = int(input())
  	arr[i] = x
  	update(i,x)
  
  for i inrage(m+k):
  	a,b,c - map(int, input().sjplit())
  	# 업데이트 연산인 경우
  	if a == 1:
  		update(b,c - arr[b]) # 바뀐 크기(dif)만큼 적용
  		arr[b] = c
  	# 구간 합(interval sum)인 경우
  	else:
  		print(interval_sum(b,c))
  ```



## 정렬 알고리즘

- `정렬(Sorting)' 이란 데이터를 특정한 기준에 따라 순서대로 나열
- 일반적으로 문제 상황에 따라서 적절한 정렬 알고리즘이 공식처럼 사용

### 선택 정렬 알고리즘

- 처리되지 않은 데이터 중 가장 작은 데이터를 선택해 맨 앞에 있는 데이터와 바꾸는 것
  1. 처리되지 않은 데이터 중 가장작은 데이터와 가장 앞의 데이터와 바꾼다
  2. 1번 반복 순차적으로 바꿔줌 

- ``` python
  array = [7,5,9,0,3,1,6,2,4,8]
  for i in range(len(array)):
  	min_index = i # 가장 작은 원소의 인덱스
  	for j in range(i+1, len(array)):
  		if array[min_index] > array[j]:
  			min_index = j
  	array [i], array[min_index] = array[min_index], array[i] # 스와프
  print(array) 
  ```

- 선택 정렬의 시간 복잡도

  - 선택 정렬은 N번 만큼 가장 작은 수를 찾아서 맨 앞으로 보내야 한다

  - 구현 방식에 따라서 사소한 오차는 있을 수 있지만, 전체 연산 횟수는 다음과 같다

  - ```
    N + (N-1) + (N-2) + ... +2
    ```

  - 이는 (N²+N-2)/2로 표현할 수 있는데, 빅오 표기법에 따라서 O(N²)라고 작성한다.

### 삽입 정렬

- 처리되지 않은 데이터를 하나씩 골라 적절한 위치에 삽입

- 선택 정렬에 비해 구현 난이도가 높은 편이지만 더 효율적으로 동작

  1. 첫 번째 데이터는 그 자체로 정렬이 되어 있다고 판단하고 두 번째 데이터가 어떤 위치로 들어갈지 판단한다. 첫 번째 데이터의 왼쪽으로 들어가거나 오른쪽으로 들어가거나 두 경우만 존재
  2.  1번 반복 

- ``` python
  array = [7,5,9,0,3,1,6,2,4,8]
  for i in range(1, len(array)):
  	for j in range(i, 0, -1): # 인덱스 i부터 1까지 1씩 감소하며 반복하는 문법
  		if array[j] < array[j - 1]: # 한 칸씩 왼쪽으로 이동
  			array[j], array[j-1] = array[j-1], array[j]
  		else: # 자기보다 작은 데이터를 만나면 그 위치에서 멈춤
  			break
  print(array)
  ```

- 삽입 정렬의 시간 복잡도

  - 삽입 정렬의 시간 복잡도는 O(N²)이며, 선택 정렬과 마찬가지로 반복문이 두 번 중첩되어 사용

  - 삽입 정렬은 현재 리스트의 데이터가 거의 정렬되어 있는 상태라면 매우 빠르게 동작

    - 최선의 경우 O(N)의 시간 복잡도를 가진다.

      